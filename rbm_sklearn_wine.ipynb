{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Ren√© Parlange, MSc\n","### üìö Machine Learning Course, PhD in Computer Science\n","#### üéì Instructor: Juan Carlos Cuevas Tello, PhD\n","#### üèõ Universidad Aut√≥noma de San Luis Potos√≠ (UASLP)\n","\n","üîó [GitHub Repository](https://github.com/parlange)"],"metadata":{"id":"Zl6MEN9OJQQa"}},{"cell_type":"markdown","source":["## Restricted Boltzmann Machines using scikit-learn\n","### dataset: wine (UCI)\n","### Note: even though the dataset is continuious, hidden layers are still Bernoulli-Bernoulli"],"metadata":{"id":"c93ljYItLJ7B"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEzJ0AtNwQgH","outputId":"726e70b3-58f2-4ff2-9d20-cf2484e2e270"},"outputs":[{"output_type":"stream","name":"stdout","text":["[BernoulliRBM] Iteration 1, pseudo-likelihood = -8.44, time = 0.00s\n","[BernoulliRBM] Iteration 2, pseudo-likelihood = -8.27, time = 0.00s\n","[BernoulliRBM] Iteration 3, pseudo-likelihood = -8.19, time = 0.00s\n","[BernoulliRBM] Iteration 4, pseudo-likelihood = -8.18, time = 0.00s\n","[BernoulliRBM] Iteration 5, pseudo-likelihood = -8.15, time = 0.00s\n","[BernoulliRBM] Iteration 6, pseudo-likelihood = -8.18, time = 0.00s\n","[BernoulliRBM] Iteration 7, pseudo-likelihood = -8.17, time = 0.00s\n","[BernoulliRBM] Iteration 8, pseudo-likelihood = -8.17, time = 0.00s\n","[BernoulliRBM] Iteration 9, pseudo-likelihood = -8.20, time = 0.00s\n","[BernoulliRBM] Iteration 10, pseudo-likelihood = -8.20, time = 0.00s\n","\n","Logistic regression using RBM features:\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.93      0.90        14\n","           1       0.67      0.88      0.76        16\n","           2       1.00      0.00      0.00         6\n","\n","    accuracy                           0.75        36\n","   macro avg       0.84      0.60      0.55        36\n","weighted avg       0.80      0.75      0.68        36\n","\n","\n","Logistic regression using raw data:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        14\n","           1       1.00      1.00      1.00        16\n","           2       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00        36\n","   macro avg       1.00      1.00      1.00        36\n","weighted avg       1.00      1.00      1.00        36\n","\n","\n","\n","Execution time for rbm_features_classifier: 0.05685591697692871 seconds\n","\n","Execution time for raw_data_classifier: 0.013712167739868164 seconds\n"]}],"source":["import numpy as np\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import minmax_scale\n","from sklearn import linear_model\n","from sklearn.neural_network import BernoulliRBM\n","from sklearn.pipeline import Pipeline\n","from sklearn import metrics\n","import time\n","\n","# Load data\n","wine = datasets.load_wine()\n","X = np.asarray(wine.data, \"float32\")\n","Y = wine.target\n","\n","# Scale data\n","X = minmax_scale(X, feature_range=(0, 1))\n","\n","# Split data\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n","\n","# Model components and pipeline\n","logistic = linear_model.LogisticRegression(solver='newton-cg', tol=1)\n","rbm = BernoulliRBM(random_state=0, verbose=True)\n","rbm_features_classifier = Pipeline(steps=[(\"rbm\", rbm), (\"logistic\", logistic)])\n","\n","# Set hyperparameters\n","rbm.learning_rate = 0.06\n","rbm.n_iter = 10\n","rbm.n_components = 10\n","logistic.C = 6000\n","\n","# Train rbm_features_classifier and print its execution time\n","start_time_rbm = time.time()\n","rbm_features_classifier.fit(X_train, Y_train)\n","\n","# Train raw_data_classifier and print its execution time\n","start_time_raw = time.time()\n","raw_data_classifier = linear_model.LogisticRegression(solver='newton-cg', tol=1, C=100.0)\n","raw_data_classifier.fit(X_train, Y_train)\n","\n","# Evaluate models\n","Y_pred = rbm_features_classifier.predict(X_test)\n","print(\"\\nLogistic regression using RBM features:\\n%s\\n\" % metrics.classification_report(Y_test, Y_pred, zero_division=1))\n","\n","Y_pred = raw_data_classifier.predict(X_test)\n","print(\"Logistic regression using raw data:\\n%s\\n\" % metrics.classification_report(Y_test, Y_pred, zero_division=1))\n","\n","print(\"\\nExecution time for rbm_features_classifier:\", time.time() - start_time_rbm, \"seconds\")\n","print(\"\\nExecution time for raw_data_classifier:\", time.time() - start_time_raw, \"seconds\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"uz1-buNDCqCi"},"execution_count":null,"outputs":[]}]}
